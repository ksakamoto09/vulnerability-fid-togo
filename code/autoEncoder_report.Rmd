---
title: "PCA vs Autoencoder Togo"
author: "Kaz Sakamoto"
date: "8/1/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
library(dplyr)
library(tidyr)
# library(ggbiplot)
library(ggplot2)
library(h2o)

### set root directory
root <- rprojroot::find_rstudio_root_file()
```

## Autoencoder

This code will initiate the H2o cluster.
```{r}
h2o.no_progress()  # turn off progress bars
h2o.init(max_mem_size = "5g")
```

```{r}
togoh2o <- h2o::as.h2o(togoScale)
# Train an autoencoder
ae1 <- h2o.deeplearning(
  x = names(togoh2o),
  training_frame = togoh2o,
  autoencoder = TRUE,
  hidden = 3, ## this will be basically how many principal components there are.
  activation = 'Tanh',
  sparse = TRUE,
  ignore_const_cols = TRUE,
)

ae1
ae1_codings <- h2o.deepfeatures(ae1, togoh2o, layer = 1)
```

```{r}
ae1Plot <- ae1_codings %>% tibble::as_tibble() %>%
  #mutate(label  = togo$adm_3, group = togo$adm_1) %>%
  dplyr::rename(PC1 = `DF.L1.C1`,
         PC2 = `DF.L1.C2`)

ae1Plot %>%
  mutate(admin = togoLong$adm_1) %>%
  ggplot(aes(x = PC1, y = PC2, color = admin)) +
  geom_point() +
  theme_minimal()

```

```{r}
pcaRecon <- function(pca, x, k){
  mu <- matrix(rep(pca$center, nrow(pca$x)), nrow = nrow(pca$x), byrow = T)
  recon <- pca$x[,1:k] %*% t(pca$rotation[,1:k]) + mu
  mse <- mean((recon - x)^2)
  return(list(x = recon, mse = mse))
}
xhat <- rep(NA, 10)
for(k in 1:10){
  xhat[k] <- pcaRecon(togoPCA, togo %>%
                        as.matrix(), k)$mse
}
aeMse <- rep(NA, 10)
for(k in 1:10){
  ae1 <- h2o.deeplearning(
  x = names(togoh2o),
  training_frame = togoh2o,
  autoencoder = TRUE,
  hidden = k, ## this will be basically how many principal components there are.
  activation = 'Tanh',
  sparse = TRUE,
  ignore_const_cols = TRUE,
)
h2oPred <- predict(ae1, togoh2o)
  aeMse[k] <- mean((as.matrix(h2oPred) - togo %>%
                        as.matrix())^2)
}
msedf <- data.frame(k = c(1:10, 1:10), mse = c(xhat, aeMse), method = c(rep("pca", 10), rep("autoencoder", 10)))
```

```{r}
print(msedf)
```

```{r}
ggplot(msedf, aes(x = k, y = mse, col = method)) + geom_line()

```

```{r}
h2o.removeAll() ## clean slate - just in case the cluster was already running

```

## Keras

```{r}
library(keras)
K <- keras::backend()
```

```{r}
togoMatrix <- togoScale %>%
  as.matrix()
```

```{r}
# This is the size of our encoded representations
encoding_dim = 5  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats

# This is our input image
enc_input = layer_input(shape=12)
# "encoded" is the encoded representation of the input
encoded <-  enc_input %>%  
  layer_dense(units = 12, activation='relu') %>%
  layer_activation_leaky_relu() %>%
  layer_dense(units=5) %>%
  layer_activation_leaky_relu()

encoder = keras_model(enc_input, encoded)
summary(encoder)

dec_input = layer_input(shape=5)
dec_output = dec_input %>%
  layer_dense(units=12, activation = "relu") %>%
  layer_activation_leaky_relu() %>%
  layer_dense(units = 12, activation = "sigmoid") %>%
  layer_activation_leaky_relu()

decoder = keras_model(dec_input, dec_output)
 
summary(decoder)
```

```{r}

aen_input = layer_input(shape=12)
aen_output = aen_input %>%
  encoder() %>%
  decoder()
   
aen = keras_model(aen_input, aen_output)
summary(aen)

```

```{r}
encoded_imgs = encoder %>% predict(togoMatrix)
decoded_imgs = decoder %>% predict(encoded_imgs)
```